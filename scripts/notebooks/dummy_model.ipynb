{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import time\n",
    "import itertools\n",
    "import os\n",
    "import datetime\n",
    "import functools\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Some runtime optimizations for CPU (using tur nodes)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = 32\n",
    "tf.config.threading.set_inter_op_parallelism_threads(32)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(16)\n",
    "tf.config.set_soft_device_placement(enabled)\n",
    "tf.config.optimizer.set_jit(\n",
    "    True\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "import pymc4 as pm\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "import covid19_npis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-03 08:58:04 wollex root[9753] WARNING Running in eager mode!\n"
     ]
    }
   ],
   "source": [
    "\"\"\" # Debugging and other snippets\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Logs setup\n",
    "log = logging.getLogger()\n",
    "# Needed to set logging level before importing other modules\n",
    "# log.setLevel(logging.DEBUG)\n",
    "covid19_npis.utils.setup_colored_logs()\n",
    "logging.getLogger(\"parso.python.diff\").disabled = True\n",
    "# Mute Tensorflow warnings ...\n",
    "# logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "if tf.executing_eagerly():\n",
    "    log.warning(\"Running in eager mode!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-03 08:58:08 wollex covid19_npis.data[9753] INFO Loaded data for Germany.\n",
      "2021-06-03 08:58:09 wollex covid19_npis.data[9753] INFO Loaded data for Belgium.\n",
      "2021-06-03 08:58:09 wollex covid19_npis.data[9753] INFO Loaded data for Portugal.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" # 1. Data Retrieval\n",
    "    Load data for different countries/regions, for now we have to define every\n",
    "    country by hand maybe we want to automatize that at some point.\n",
    "\n",
    "    TODO: maybe we want to outsource that to a different file at some point\n",
    "\"\"\"\n",
    "\n",
    "# Load our data from csv files into our own custom data classes\n",
    "\n",
    "countries = [\n",
    "    \"Germany\",\n",
    "    \"Belgium\",\n",
    "    #    \"Czechia\",\n",
    "    # \"Denmark\",\n",
    "    # \"Finland\",\n",
    "    # \"Greece\",\n",
    "    # \"Italy\",\n",
    "    # \"Netherlands\",\n",
    "    \"Portugal\",\n",
    "    # \"Romania\",\n",
    "    # \"Spain\",\n",
    "    # \"Sweden\",\n",
    "    # \"Switzerland\",\n",
    "]\n",
    "\n",
    "c = [\n",
    "    covid19_npis.data.Country(f\"../../data/coverage_db/{country}\",)\n",
    "    for country in countries\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct our modelParams from the data.\n",
    "modelParams = covid19_npis.ModelParams(countries=c, minimal_daily_deaths=1)\n",
    "# modelParams = covid19_npis.ModelParams.from_folder(\"../data/Germany_bundesl√§nder/\")\n",
    "\n",
    "# Define our model\n",
    "this_model = covid19_npis.model.model.main_model(modelParams)\n",
    "\n",
    "# Test shapes, should be all 3:\n",
    "def print_dist_shapes(st):\n",
    "    for name, dist in itertools.chain(\n",
    "        st.discrete_distributions.items(), st.continuous_distributions.items(),\n",
    "    ):\n",
    "        if dist.log_prob(st.all_values[name]).shape != (3,):\n",
    "            log.warning(\n",
    "                f\"False shape: {dist.log_prob(st.all_values[name]).shape}, {name}\"\n",
    "            )\n",
    "    for p in st.potentials:\n",
    "        if p.value.shape != (3,):\n",
    "            log.warning(f\"False shape: {p.value.shape} {p.name}\")\n",
    "\n",
    "\n",
    "_, sample_state = pm.evaluate_model_transformed(this_model, sample_shape=(3,))\n",
    "print_dist_shapes(sample_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-03 08:58:30 wollex tensorflow[9753] WARNING From /home/wollex/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "2021-06-03 08:58:30 wollex tensorflow[9753] WARNING From /home/wollex/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"  # 2. MCMC Sampling\n",
    "\"\"\"\n",
    "num_chains = 6\n",
    "use_VI = True\n",
    "jit_compile = True\n",
    "\n",
    "if use_VI:\n",
    "    begin_time = time.time()\n",
    "    from tensorflow_probability import distributions as tfd\n",
    "    from tensorflow_probability import bijectors as tfb\n",
    "    \n",
    "    \n",
    "    _, state = pm.evaluate_model_transformed(this_model)\n",
    "    state, _ = state.as_sampling_state()\n",
    "\n",
    "    \"\"\"\n",
    "    Retrieve the name of all transformed distributions \n",
    "    \"\"\"\n",
    "    values_dict = dict(state.all_unobserved_values)\n",
    "    transformed_names = list(values_dict.keys())\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Construct joined distribution from a sample of all prior distributions. \n",
    "    (not taking noise into respect)\n",
    "    # Note: Does this correspond to the variational parameters Phi, in the sticking the landing paper?\n",
    "    \"\"\"\n",
    "    # Note: Why Normal distribution as base? Shouldn't that depend on the underlying distribution?\n",
    "    normal_base = tfd.JointDistributionNamed(\n",
    "        {\n",
    "            name: tfd.Sample(tfd.Normal(loc=0.0, scale=1.0), sample_shape=tensor.shape)\n",
    "            for name, tensor in values_dict.items()\n",
    "        },\n",
    "        validate_args=False,\n",
    "        name=\"normal_base\",\n",
    "    )\n",
    "\n",
    "    # Note: What is this abomination? Can we apply some make-up please?\n",
    "    order_list = [\"left-to-right\", \"right-to-left\", \"left-to-right\"]\n",
    "\n",
    "    bijector = covid19_npis.model.build_iaf(values_dict, order_list)\n",
    "\n",
    "    \"\"\"We transform our joined distribution with the previously created bijector.\n",
    "    \"\"\"\n",
    "    posterior_approx = tfd.TransformedDistribution(normal_base, bijector=bijector)\n",
    "\n",
    "    sample_size = 4\n",
    "\n",
    "    (\n",
    "        logpfn,\n",
    "        init_random,\n",
    "        _deterministics_callback,\n",
    "        deterministic_names,\n",
    "        state_,\n",
    "    ) = pm.mcmc.samplers.build_logp_and_deterministic_functions(\n",
    "        this_model, num_chains=sample_size, collect_reduced_log_prob=False\n",
    "    )\n",
    "\n",
    "    trace_loss = lambda traceable_quantities: tf.debugging.check_numerics(\n",
    "        traceable_quantities.loss, f\"loss not finite: {traceable_quantities.loss}\"\n",
    "    )\n",
    "\n",
    "    # For eventual debugging:\n",
    "    # tf.config.run_functions_eagerly(True)\n",
    "    # tf.debugging.enable_check_numerics(stack_height_limit=50, path_length_limit=50)\n",
    "\n",
    "    begin = time.time()\n",
    "        \n",
    "    if jit_compile:\n",
    "        # Run the entire minimization inside a jit-compiled function. \n",
    "        @tf.function(autograph=False, experimental_compile=True)\n",
    "        def fit_surrogate_posterior(*args, **kwargs):\n",
    "            return tfp.vi.fit_surrogate_posterior(*args, **kwargs)\n",
    "    else: \n",
    "        fit_surrogate_posterior = tfp.vi.fit_surrogate_posterior\n",
    "    \n",
    "    \n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.003,\n",
    "    decay_steps=5_000,\n",
    "    decay_rate=0.3,\n",
    "    staircase=False)\n",
    "\n",
    "    \n",
    "    loss_arr = fit_surrogate_posterior(\n",
    "        logpfn,\n",
    "        posterior_approx,\n",
    "        tf.optimizers.Adam(\n",
    "            learning_rate=lr_schedule, epsilon=1e-7, beta_1=0.9, beta_2=0.999, clipvalue=10.0\n",
    "        ),\n",
    "        100_000,\n",
    "        convergence_criterion=tfp.optimizer.convergence_criteria.LossNotDecreasing(\n",
    "            atol=0.02, rtol=None, window_size=2_000, min_num_steps=10_000),\n",
    "        sample_size=sample_size,\n",
    "        trainable_variables=None,\n",
    "        #jit_compile=True,\n",
    "        variational_loss_fn=functools.partial(\n",
    "            tfp.vi.monte_carlo_variational_loss,\n",
    "            discrepancy_fn=tfp.vi.kl_reverse,\n",
    "            use_reparameterization=True,\n",
    "        ),\n",
    "        trace_fn=trace_loss,\n",
    "    )\n",
    "    loss_arr = loss_arr[np.array(loss_arr!=loss_arr[-1])]\n",
    "    log.info(f\"Likelihood: {np.mean(loss_arr[-1000:])}\")\n",
    "\n",
    "    _, st = pm.evaluate_model_posterior_predictive(\n",
    "        this_model, values=posterior_approx.sample(100)\n",
    "    )\n",
    "    var_names = list(st.all_values.keys()) + list(st.deterministics_values.keys())\n",
    "    samples = {\n",
    "        k: (\n",
    "            st.untransformed_values[k]\n",
    "            if k in st.untransformed_values\n",
    "            else (\n",
    "                st.deterministics_values[k]\n",
    "                if k in st.deterministics_values\n",
    "                else st.transformed_values[k]\n",
    "            )\n",
    "        )\n",
    "        for k in var_names\n",
    "    }\n",
    "\n",
    "\n",
    "    init_state = posterior_approx.sample(num_chains)\n",
    "    init_state = [init_state[name] for name in transformed_names]\n",
    "    bijector_to_list = tfb.Restructure(\n",
    "        [name for name in transformed_names], {name: name for name in transformed_names}\n",
    "    )\n",
    "    bijector_list = tfb.Chain(\n",
    "        [bijector_to_list, bijector, tfb.Invert(bijector_to_list)]\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    log.info(\"running time: {:.1f}s\".format(end_time - begin_time))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(loss_arr)\n",
    "    plt.title(\"Tuning bijector\")\n",
    "    plt.ylabel('Likelihood')\n",
    "    plt.xlabel('optimization step')\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    bijector_list = None\n",
    "    init_state = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_time = time.time()\n",
    "log.info(\"start\")\n",
    "\n",
    "\n",
    "trace_tuning, trace = pm.sample(\n",
    "    this_model,\n",
    "    num_samples=1000,\n",
    "    num_samples_binning=10,\n",
    "    burn_in_min=10,\n",
    "    burn_in=2000,\n",
    "    use_auto_batching=False,\n",
    "    num_chains=num_chains,\n",
    "    xla=False,\n",
    "    initial_step_size=0.001,\n",
    "    ratio_tuning_epochs=1.3,\n",
    "    max_tree_depth=4,\n",
    "    decay_rate=0.75,\n",
    "    target_accept_prob=0.75,\n",
    "    step_size_adaption_per_chain=False,\n",
    "    bijector=bijector_list,\n",
    "    init_state=init_state\n",
    "    # num_steps_between_results = 9,\n",
    "    #    state=pm.evaluate_model_transformed(this_model)[1]\n",
    "    # sampler_type=\"nuts\",\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "log.info(\"running time: {:.1f}s\".format(end_time - begin_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(trace_tuning.sample_stats[\"step_size\"][0])\n",
    "plt.figure()\n",
    "plt.plot(trace_tuning.sample_stats[\"lp\"].T)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also Sample the prior for the kde in the plots (optional)\n",
    "trace_prior = pm.sample_prior_predictive(\n",
    "    this_model, sample_shape=(500,), use_auto_batching=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = f'./../traces/{datetime.datetime.now().strftime(\"%y_%m_%d_%H\")}'\n",
    "\n",
    "# Save our traces for the plotting script\n",
    "store = covid19_npis.utils.save_trace_zarr(\n",
    "#store = covid19_npis.utils.save_trace(\n",
    "    trace, modelParams, store=fpath, trace_prior=trace_prior,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath='./traces/21_05_27_09/21_05_27_09_21'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wollex/Data/Science/Corona/covid19_npis_europe/scripts/notebooks\n"
     ]
    }
   ],
   "source": [
    "cd notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f\"python ./../plot_trace.py {fpath}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
